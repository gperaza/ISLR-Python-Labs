{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab on Ridge Regression and the Lasso is a Python adaptation of p. 251-255 of \"Introduction to Statistical Learning with Applications in R\" by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani. Adapted by R. Jordan Crouser at Smith College for SDS293: Machine Learning (Spring 2016).\n",
    "\n",
    "# 6.6: Ridge Regression and the Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `sklearn` package in order to perform ridge regression and\n",
    "the lasso. The main functions in this package that we care about are `Ridge()`, which can be used\n",
    "to fit ridge regression models, and `Lasso()` which will fit lasso models. They also have cross-validated counterparts: `RidgeCV()` and `LassoCV()`. We'll use these a bit later.\n",
    "\n",
    "Before proceeding, let's first ensure that the missing values have\n",
    "been removed from the data, as described in the previous lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 263 entries, -Alan Ashby to -Willie Wilson\n",
      "Data columns (total 20 columns):\n",
      "AtBat        263 non-null int64\n",
      "Hits         263 non-null int64\n",
      "HmRun        263 non-null int64\n",
      "Runs         263 non-null int64\n",
      "RBI          263 non-null int64\n",
      "Walks        263 non-null int64\n",
      "Years        263 non-null int64\n",
      "CAtBat       263 non-null int64\n",
      "CHits        263 non-null int64\n",
      "CHmRun       263 non-null int64\n",
      "CRuns        263 non-null int64\n",
      "CRBI         263 non-null int64\n",
      "CWalks       263 non-null int64\n",
      "League       263 non-null object\n",
      "Division     263 non-null object\n",
      "PutOuts      263 non-null int64\n",
      "Assists      263 non-null int64\n",
      "Errors       263 non-null int64\n",
      "Salary       263 non-null float64\n",
      "NewLeague    263 non-null object\n",
      "dtypes: float64(1), int64(16), object(3)\n",
      "memory usage: 43.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Data/Hitters.csv', index_col=0).dropna()\n",
    "df.info()\n",
    "dummies = pd.get_dummies(df[['League', 'Division', 'NewLeague']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now perform ridge regression and the lasso in order to predict `Salary` on\n",
    "the `Hitters` data. Let's set up our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 263 entries, -Alan Ashby to -Willie Wilson\n",
      "Data columns (total 19 columns):\n",
      "AtBat          263 non-null float64\n",
      "Hits           263 non-null float64\n",
      "HmRun          263 non-null float64\n",
      "Runs           263 non-null float64\n",
      "RBI            263 non-null float64\n",
      "Walks          263 non-null float64\n",
      "Years          263 non-null float64\n",
      "CAtBat         263 non-null float64\n",
      "CHits          263 non-null float64\n",
      "CHmRun         263 non-null float64\n",
      "CRuns          263 non-null float64\n",
      "CRBI           263 non-null float64\n",
      "CWalks         263 non-null float64\n",
      "PutOuts        263 non-null float64\n",
      "Assists        263 non-null float64\n",
      "Errors         263 non-null float64\n",
      "League_N       263 non-null uint8\n",
      "Division_W     263 non-null uint8\n",
      "NewLeague_N    263 non-null uint8\n",
      "dtypes: float64(16), uint8(3)\n",
      "memory usage: 35.7+ KB\n"
     ]
    }
   ],
   "source": [
    "y = df.Salary\n",
    "\n",
    "# Drop the column with the independent variable (Salary), and columns for which we created dummy variables\n",
    "X_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis = 1).astype('float64')\n",
    "\n",
    "# Define the feature set X.\n",
    "X = pd.concat([X_, dummies[['League_N', 'Division_W', 'NewLeague_N']]], axis = 1)\n",
    "\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.6.1 Ridge Regression\n",
    "The `Ridge()` function has an alpha argument ($\\lambda$, but with a different name!) that is used to tune the model. We'll generate an array of alpha values ranging from very big to very small, essentially\n",
    "covering the full range of scenarios from the null model containing\n",
    "only the intercept, to the least squares fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5.00000000e+09,   3.78231664e+09,   2.86118383e+09,\n",
       "         2.16438064e+09,   1.63727458e+09,   1.23853818e+09,\n",
       "         9.36908711e+08,   7.08737081e+08,   5.36133611e+08,\n",
       "         4.05565415e+08,   3.06795364e+08,   2.32079442e+08,\n",
       "         1.75559587e+08,   1.32804389e+08,   1.00461650e+08,\n",
       "         7.59955541e+07,   5.74878498e+07,   4.34874501e+07,\n",
       "         3.28966612e+07,   2.48851178e+07,   1.88246790e+07,\n",
       "         1.42401793e+07,   1.07721735e+07,   8.14875417e+06,\n",
       "         6.16423370e+06,   4.66301673e+06,   3.52740116e+06,\n",
       "         2.66834962e+06,   2.01850863e+06,   1.52692775e+06,\n",
       "         1.15506485e+06,   8.73764200e+05,   6.60970574e+05,\n",
       "         5.00000000e+05,   3.78231664e+05,   2.86118383e+05,\n",
       "         2.16438064e+05,   1.63727458e+05,   1.23853818e+05,\n",
       "         9.36908711e+04,   7.08737081e+04,   5.36133611e+04,\n",
       "         4.05565415e+04,   3.06795364e+04,   2.32079442e+04,\n",
       "         1.75559587e+04,   1.32804389e+04,   1.00461650e+04,\n",
       "         7.59955541e+03,   5.74878498e+03,   4.34874501e+03,\n",
       "         3.28966612e+03,   2.48851178e+03,   1.88246790e+03,\n",
       "         1.42401793e+03,   1.07721735e+03,   8.14875417e+02,\n",
       "         6.16423370e+02,   4.66301673e+02,   3.52740116e+02,\n",
       "         2.66834962e+02,   2.01850863e+02,   1.52692775e+02,\n",
       "         1.15506485e+02,   8.73764200e+01,   6.60970574e+01,\n",
       "         5.00000000e+01,   3.78231664e+01,   2.86118383e+01,\n",
       "         2.16438064e+01,   1.63727458e+01,   1.23853818e+01,\n",
       "         9.36908711e+00,   7.08737081e+00,   5.36133611e+00,\n",
       "         4.05565415e+00,   3.06795364e+00,   2.32079442e+00,\n",
       "         1.75559587e+00,   1.32804389e+00,   1.00461650e+00,\n",
       "         7.59955541e-01,   5.74878498e-01,   4.34874501e-01,\n",
       "         3.28966612e-01,   2.48851178e-01,   1.88246790e-01,\n",
       "         1.42401793e-01,   1.07721735e-01,   8.14875417e-02,\n",
       "         6.16423370e-02,   4.66301673e-02,   3.52740116e-02,\n",
       "         2.66834962e-02,   2.01850863e-02,   1.52692775e-02,\n",
       "         1.15506485e-02,   8.73764200e-03,   6.60970574e-03,\n",
       "         5.00000000e-03])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = 10**np.linspace(10,-2,100)*0.5\n",
    "alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associated with each alpha value is a vector of ridge regression coefficients, which we'll\n",
    "store in a matrix `coefs`. In this case, it is a $19 \\times 100$\n",
    "matrix, with 19 rows (one for each predictor) and 100\n",
    "columns (one for each value of alpha). Remember that we'll want to standardize the\n",
    "variables so that they are on the same scale. To do this, we can use the\n",
    "`normalize = True` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 19)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge(normalize = True)\n",
    "coefs = []\n",
    "\n",
    "for a in alphas:\n",
    "    ridge.set_params(alpha = a)\n",
    "    ridge.fit(X, y)\n",
    "    coefs.append(ridge.coef_)\n",
    "    \n",
    "np.shape(coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect the coefficient estimates to be much smaller, in terms of $l_2$ norm,\n",
    "when a large value of alpha is used, as compared to when a small value of alpha is\n",
    "used. Let's plot and find out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'weights')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEOCAYAAABIESrBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8QwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffaf4ab2eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.gca()\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split the samples into a training set and a test set in order\n",
    "to estimate the test error of ridge regression and the lasso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test , y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we fit a ridge regression model on the training set, and evaluate\n",
    "its MSE on the test set, using $\\lambda = 4$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AtBat           0.098658\n",
      "Hits            0.446094\n",
      "HmRun           1.412107\n",
      "Runs            0.660773\n",
      "RBI             0.843403\n",
      "Walks           1.008473\n",
      "Years           2.779882\n",
      "CAtBat          0.008244\n",
      "CHits           0.034149\n",
      "CHmRun          0.268634\n",
      "CRuns           0.070407\n",
      "CRBI            0.070060\n",
      "CWalks          0.082795\n",
      "PutOuts         0.104747\n",
      "Assists        -0.003739\n",
      "Errors          0.268363\n",
      "League_N        4.241051\n",
      "Division_W    -30.768885\n",
      "NewLeague_N     4.123474\n",
      "dtype: float64\n",
      "106216.52238\n"
     ]
    }
   ],
   "source": [
    "ridge2 = Ridge(alpha = 4, normalize = True)\n",
    "ridge2.fit(X_train, y_train)             # Fit a ridge regression on the training data\n",
    "pred2 = ridge2.predict(X_test)           # Use this model to predict the test data\n",
    "print(pd.Series(ridge2.coef_, index = X.columns)) # Print coefficients\n",
    "print(mean_squared_error(y_test, pred2))          # Calculate the test MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test MSE when alpha = 4 is 106216. Now let's see what happens if we use a huge value of alpha, say $10^{10}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AtBat          1.317464e-10\n",
      "Hits           4.647486e-10\n",
      "HmRun          2.079865e-09\n",
      "Runs           7.726175e-10\n",
      "RBI            9.390640e-10\n",
      "Walks          9.769219e-10\n",
      "Years          3.961442e-09\n",
      "CAtBat         1.060533e-11\n",
      "CHits          3.993605e-11\n",
      "CHmRun         2.959428e-10\n",
      "CRuns          8.245247e-11\n",
      "CRBI           7.795451e-11\n",
      "CWalks         9.894387e-11\n",
      "PutOuts        7.268991e-11\n",
      "Assists       -2.615885e-12\n",
      "Errors         2.084514e-10\n",
      "League_N      -2.501281e-09\n",
      "Division_W    -1.549951e-08\n",
      "NewLeague_N   -2.023196e-09\n",
      "dtype: float64\n",
      "172862.235804\n"
     ]
    }
   ],
   "source": [
    "ridge3 = Ridge(alpha = 10**10, normalize = True)\n",
    "ridge3.fit(X_train, y_train)             # Fit a ridge regression on the training data\n",
    "pred3 = ridge3.predict(X_test)           # Use this model to predict the test data\n",
    "print(pd.Series(ridge3.coef_, index = X.columns)) # Print coefficients\n",
    "print(mean_squared_error(y_test, pred3))          # Calculate the test MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This big penalty shrinks the coefficients to a very large degree, essentially reducing to a model containing just the intercept. This over-shrinking makes the model more biased, resulting in a higher MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so fitting a ridge regression model with alpha = 4 leads to a much lower test\n",
    "MSE than fitting a model with just an intercept. We now check whether\n",
    "there is any benefit to performing ridge regression with alpha = 4 instead of\n",
    "just performing least squares regression. Recall that least squares is simply\n",
    "ridge regression with alpha = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AtBat           -1.821115\n",
      "Hits             4.259156\n",
      "HmRun           -4.773401\n",
      "Runs            -0.038760\n",
      "RBI              3.984578\n",
      "Walks            3.470126\n",
      "Years            9.498236\n",
      "CAtBat          -0.605129\n",
      "CHits            2.174979\n",
      "CHmRun           2.979306\n",
      "CRuns            0.266356\n",
      "CRBI            -0.598456\n",
      "CWalks           0.171383\n",
      "PutOuts          0.421063\n",
      "Assists          0.464379\n",
      "Errors          -6.024576\n",
      "League_N       133.743163\n",
      "Division_W    -113.743875\n",
      "NewLeague_N    -81.927763\n",
      "dtype: float64\n",
      "116690.468567\n"
     ]
    }
   ],
   "source": [
    "ridge2 = Ridge(alpha = 0, normalize = True)\n",
    "ridge2.fit(X_train, y_train)             # Fit a ridge regression on the training data\n",
    "pred = ridge2.predict(X_test)            # Use this model to predict the test data\n",
    "print(pd.Series(ridge2.coef_, index = X.columns)) # Print coefficients\n",
    "print(mean_squared_error(y_test, pred))           # Calculate the test MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we are indeed improving over regular least-squares!\n",
    "\n",
    "Instead of arbitrarily choosing alpha $ = 4$, it would be better to\n",
    "use cross-validation to choose the tuning parameter alpha. We can do this using\n",
    "the cross-validated ridge regression function, `RidgeCV()`. By default, the function\n",
    "performs generalized cross-validation (an efficient form of LOOCV), though this can be changed using the\n",
    "argument `cv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57487849769886779"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgecv = RidgeCV(alphas = alphas, scoring = 'neg_mean_squared_error', normalize = True)\n",
    "ridgecv.fit(X_train, y_train)\n",
    "ridgecv.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we see that the value of alpha that results in the smallest cross-validation\n",
    "error is 0.57. What is the test MSE associated with this value of\n",
    "alpha?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridge4 = Ridge(alpha = ridgecv.alpha_, normalize = True)\n",
    "ridge4.fit(X_train, y_train)\n",
    "mean_squared_error(y_test, ridge4.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This represents a further improvement over the test MSE that we got using\n",
    "alpha $ = 4$. Finally, we refit our ridge regression model on the full data set,\n",
    "using the value of alpha chosen by cross-validation, and examine the coefficient\n",
    "estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridge4.fit(X, y)\n",
    "pd.Series(ridge4.coef_, index = X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, none of the coefficients are exactly zero - ridge regression does not\n",
    "perform variable selection!\n",
    "\n",
    "# 6.6.2 The Lasso\n",
    "We saw that ridge regression with a wise choice of alpha can outperform least\n",
    "squares as well as the null model on the Hitters data set. We now ask\n",
    "whether the lasso can yield either a more accurate or a more interpretable\n",
    "model than ridge regression. In order to fit a lasso model, we'll\n",
    "use the `Lasso()` function; however, this time we'll need to include the argument `max_iter = 10000`.\n",
    "Other than that change, we proceed just as we did in fitting a ridge model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso = Lasso(max_iter = 10000, normalize = True)\n",
    "coefs = []\n",
    "\n",
    "for a in alphas:\n",
    "    lasso.set_params(alpha=a)\n",
    "    lasso.fit(scale(X_train), y_train)\n",
    "    coefs.append(lasso.coef_)\n",
    "    \n",
    "ax = plt.gca()\n",
    "ax.plot(alphas*2, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that in the coefficient plot that depending on the choice of tuning\n",
    "parameter, some of the coefficients are exactly equal to zero. We now\n",
    "perform 10-fold cross-validation to choose the best alpha, refit the model, and compute the associated test error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lassocv = LassoCV(alphas = None, cv = 10, max_iter = 100000, normalize = True)\n",
    "lassocv.fit(X_train, y_train)\n",
    "\n",
    "lasso.set_params(alpha=lassocv.alpha_)\n",
    "lasso.fit(X_train, y_train)\n",
    "mean_squared_error(y_test, lasso.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is substantially lower than the test set MSE of the null model and of\n",
    "least squares, and only a little worse than the test MSE of ridge regression with alpha\n",
    "chosen by cross-validation.\n",
    "\n",
    "However, the lasso has a substantial advantage over ridge regression in\n",
    "that the resulting coefficient estimates are sparse. Here we see that 13 of\n",
    "the 19 coefficient estimates are exactly zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some of the coefficients are now reduced to exactly zero.\n",
    "pd.Series(lasso.coef_, index=X.columns)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
